# Tools
OPENAI_API_KEY=your_openai_api_key_here
FIRECRAWL_API_KEY=your_firecrawl_api_key_here
SERPER_API_KEY=your_serper_api_key_here
PAPPERS_API_KEY=your_pappers_api_key_here
SCRAPERAPI_KEY=

# Pappers Configuration
# Mode: light (~7 credits), medium (~15 credits), full (~39.5 credits)
# Premium tier = 1000+ credits/month: ~25 full profiles/month
PAPPERS_MODE=full
PAPPERS_INCLUDE_DECISIONS=true
PAPPERS_INCLUDE_PARCELLES=true
PAPPERS_INCLUDE_OBSERVATIONS=true
PAPPERS_INCLUDE_ENTREPRISES_DIRIGEES=true
PAPPERS_INCLUDE_BODACC_PERSON=true

# Flask Configuration
FLASK_DEBUG=1
FLASK_APP=main.py
PORT=5100

# CORS Origins (comma-separated)
CORS_ORIGINS=http://localhost:5101,http://localhost:5173

# OpenAI Configuration
OPENAI_MODEL=gpt-4o

# Scraping Configuration
# Light: 6 scrapes (~$0.06), Medium: 10 scrapes (~$0.10), Deep: 15 scrapes (~$0.15)
# Premium: 50 scrapes (~$0.50) - Enables LinkedIn activity analysis + comprehensive web scraping
# More scrapes = more comprehensive analysis but longer processing time (2-3min for premium)
MAX_TOTAL_SCRAPES=50

# Firecrawl Premium Configuration
# Max concurrent scraping jobs (Premium supports up to 5 parallel jobs)
# Higher = faster but more API load. Recommended: 5 for premium, 1 for free tier
FIRECRAWL_MAX_CONCURRENT_JOBS=5

# Timeout per scrape in seconds (prevents hanging on heavy pages)
# Recommended: 30-60s for most sites. GitHub datasets can timeout at 60s.
FIRECRAWL_TIMEOUT_SECONDS=45

# Rate limiting (seconds between scrapes when not using concurrent jobs)
# Premium has higher rate limits, can be reduced. Set to 0 to disable with concurrent jobs.
FIRECRAWL_RATE_LIMIT_SECONDS=0

# Cache Configuration
DATABASE_PATH=data/lumironscraper.db
CACHE_TTL_SECONDS=604800